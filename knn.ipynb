{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is  (16, 3072)\n"
     ]
    }
   ],
   "source": [
    "# loading images and converting them to numpy array\n",
    "# for X_train\n",
    "X_train_lst = []\n",
    "for i in range(1, 17):\n",
    "    img = cv2.imread(f\"./train/{i}.jpg\")\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    img_np = np.array(img)\n",
    "    flat_array = img_np.reshape(img_np.shape[0] * img_np.shape[1] * img_np.shape[2])\n",
    "    X_train_lst.append(flat_array)\n",
    "    \n",
    "X_train = np.array(X_train_lst)\n",
    "print(\"The shape of X_train is \",X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of y_train is  (16,)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "print(\"The shape of y_train is \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X_test\n",
    "def test_data(number_of_images):\n",
    "    X_test_lst = []\n",
    "    for i in range(1,number_of_images+1):\n",
    "        img = cv2.imread(f\"./test/{i}.jpg\")\n",
    "        img = cv2.resize(img, (32, 32))\n",
    "        img_np = np.array(img)\n",
    "        flat_array = img_np.reshape(img_np.shape[0] * img_np.shape[1] * img_np.shape[2])\n",
    "        X_test_lst.append(flat_array)\n",
    "\n",
    "    X_test = np.array(X_test_lst)\n",
    "\n",
    "    return X_test\n",
    "\n",
    "X_test = test_data(4)\n",
    "\n",
    "# for y_test\n",
    "y_test = np.array([0,0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "\n",
    "\n",
    "    def __init__(self, k, problem: int=0, metric: int=0):\n",
    "        \"\"\"\n",
    "            Parameters\n",
    "            ----------\n",
    "            k: Number of nearest self.neighbors\n",
    "            problem: Type of learning\n",
    "            0 = Regression, 1 = Classification\n",
    "            metric: Distance metric to be used. \n",
    "            0 = Euclidean, 1 = Manhattan\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.problem = problem\n",
    "        self.metric = metric\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "\n",
    "        m = self.X_train.shape[0]\n",
    "        n = X_test.shape[0]\n",
    "        y_pred = []\n",
    "\n",
    "        # Calculating distances  \n",
    "        for i in range(n):  # for every sample in X_test\n",
    "            distance = []  # To store the distances\n",
    "            for j in range(m):  # for every sample in X_train\n",
    "                if self.metric == 0:\n",
    "                    d = (np.sqrt(np.sum(np.square(X_test[i,:] - self.X_train[j,:]))))  # Euclidean distance\n",
    "                else:\n",
    "                    d = (np.absolute(X_test[i, :] - self.X_train[j,:]))  # Manhattan distance\n",
    "                distance.append((d, y_train[j]))    \n",
    "            distance = sorted(distance) # sorting distances in ascending order\n",
    "\n",
    "            # Getting k nearest neighbors\n",
    "            neighbors = []\n",
    "            for item in range(self.k):\n",
    "                neighbors.append(distance[item][1])  # appending K nearest neighbors\n",
    "                \n",
    "            # Making predictions\n",
    "            if self.problem == 0:\n",
    "                y_pred.append(np.mean(neighbors))  # For Regression\n",
    "            else:\n",
    "                # For Classification\n",
    "                votes = 0\n",
    "                for i in range(0, self.k):\n",
    "                    if neighbors[i] == 1:\n",
    "                        votes = votes+1\n",
    "                if (votes/self.k)*100 >= 50:\n",
    "                    y_pred.append(1)\n",
    "                else:\n",
    "                    y_pred.append(0)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "  accuracy = np.sum(y_true == y_pred)/len(y_true)*100\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred:  [1, 0, 0, 0]\n",
      "Accuracy 25.0\n"
     ]
    }
   ],
   "source": [
    "# for K=3\n",
    "knn = KNN(3,1,0)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"y_pred: \", y_pred)\n",
    "print(\"Accuracy\", accuracy(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred:  [0, 0, 0, 0]\n",
      "Accuracy 50.0\n"
     ]
    }
   ],
   "source": [
    "# for K=5\n",
    "knn = KNN(5,1,0)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"y_pred: \", y_pred)\n",
    "print(\"Accuracy\", accuracy(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred:  [0, 0, 0, 0]\n",
      "Accuracy 50.0\n"
     ]
    }
   ],
   "source": [
    "# for K=7\n",
    "knn = KNN(7,1,0)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"y_pred: \", y_pred)\n",
    "print(\"Accuracy\", accuracy(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "avg_intense_train = [np.mean(x) for x in X_train]\n",
    "std_deviation_train = [np.std(x) for x in X_train]\n",
    "\n",
    "avg_intense_test = [np.mean(x) for x in X_test]\n",
    "std_deviation_test = [np.std(x) for x in X_test]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(std_deviation_train[0:9],avg_intense_train[0:9], color=\"blue\")\n",
    "plt.scatter(std_deviation_train[8:17], avg_intense_train[8:17], color=\"orange\")\n",
    "plt.scatter(std_deviation_test[0:3], avg_intense_test[0:3], color = \"blue\", marker=\"*\")\n",
    "plt.scatter(std_deviation_test[2:5], avg_intense_test[2:5],color = 'orange', marker=\"*\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "\n",
    "    def __init__(self, C = 1.0):\n",
    "        # C = error term\n",
    "        self.C = C\n",
    "        self.w = 0\n",
    "        self.b = 0\n",
    "\n",
    "    # Hinge Loss Function / Calculation\n",
    "    def hingeloss(self, w, b, x, y):\n",
    "        # Regularizer term\n",
    "        reg = 0.5 * (w * w)\n",
    "\n",
    "        for i in range(x.shape[0]):\n",
    "            # Optimization term\n",
    "            opt_term = y[i] * ((np.dot(w, x[i])) + b)\n",
    "\n",
    "            # calculating loss\n",
    "            loss = reg + self.C * max(0, 1-opt_term)\n",
    "            \n",
    "        return loss[0][0]\n",
    "\n",
    "    def fit(self, X, Y, batch_size=100, learning_rate=0.001, epochs=1000):\n",
    "        # The number of features in X\n",
    "        number_of_features = X.shape[1]\n",
    "\n",
    "        # The number of Samples in X\n",
    "        number_of_samples = X.shape[0]\n",
    "\n",
    "        c = self.C\n",
    "\n",
    "        # Creating ids from 0 to number_of_samples - 1\n",
    "        ids = np.arange(number_of_samples)\n",
    "\n",
    "        # Shuffling the samples randomly\n",
    "        np.random.shuffle(ids)\n",
    "\n",
    "        # creating an array of zeros\n",
    "        w = np.random.rand(1,number_of_features)\n",
    "        b = 0\n",
    "        losses = []\n",
    "\n",
    "        # Gradient Descent logic\n",
    "        for i in range(epochs):\n",
    "            # Calculating the Hinge Loss\n",
    "            l = self.hingeloss(w, b, X, Y)\n",
    "\n",
    "            # Appending all losses \n",
    "            losses.append(l)\n",
    "            \n",
    "            # Starting from 0 to the number of samples with batch_size as interval\n",
    "            for batch_initial in range(0, number_of_samples, batch_size):\n",
    "                gradw = 0\n",
    "                gradb = 0\n",
    "\n",
    "                for j in range(batch_initial, batch_initial+ batch_size):\n",
    "                    if j < number_of_samples:\n",
    "                        x = ids[j]\n",
    "                        ti = Y[x] * (np.dot(w, X[x].T) + b)\n",
    "\n",
    "                        if ti > 1:\n",
    "                            gradw += 0\n",
    "                            gradb += 0\n",
    "                        else:\n",
    "                            # Calculating the gradients\n",
    "\n",
    "                            #w.r.t w \n",
    "                            gradw += c * Y[x] * X[x]\n",
    "                            # w.r.t b\n",
    "                            gradb += c * Y[x]\n",
    "\n",
    "                # Updating weights and bias\n",
    "                w = w - learning_rate * gradw\n",
    "                b = b - learning_rate * gradb\n",
    "        \n",
    "        self.w = w\n",
    "        self.b = b\n",
    "\n",
    "        return self.w, self.b, losses\n",
    "\n",
    "    def predict(self, X):\n",
    "        prediction = np.dot(X, self.w[0]) + self.b # w.x + b\n",
    "        return np.sign(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n",
      "Accuracy 50.0\n"
     ]
    }
   ],
   "source": [
    "svm = SVM()\n",
    "w, b, loss = svm.fit(X_train, y_train)\n",
    "pred = svm.predict(X_test)\n",
    "print(pred)\n",
    "print(\"Accuracy\", accuracy(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
